{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11397995,"sourceType":"datasetVersion","datasetId":7078972}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"64a16c60","cell_type":"markdown","source":"# 1 - Import requirements","metadata":{}},{"id":"73d0893f-7f54-4621-adc2-4f42fdaa7437","cell_type":"code","source":"# !pip install pytorch-optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:30:51.985335Z","iopub.execute_input":"2025-04-15T04:30:51.985704Z","iopub.status.idle":"2025-04-15T04:30:51.989518Z","shell.execute_reply.started":"2025-04-15T04:30:51.985675Z","shell.execute_reply":"2025-04-15T04:30:51.988612Z"}},"outputs":[],"execution_count":1},{"id":"3215f98a","cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torch.nn.functional as F\n# from pytorch_optimizer import SAM\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-04-15T04:30:51.990742Z","iopub.execute_input":"2025-04-15T04:30:51.991056Z","iopub.status.idle":"2025-04-15T04:31:00.446892Z","shell.execute_reply.started":"2025-04-15T04:30:51.991036Z","shell.execute_reply":"2025-04-15T04:31:00.446253Z"},"trusted":true},"outputs":[],"execution_count":2},{"id":"65be178d","cell_type":"markdown","source":"# 2 - Prepare data","metadata":{}},{"id":"5e540e20-ab23-474d-9626-aa733e13b49b","cell_type":"code","source":"label_mapping = {\n    'BUY': 0,\n    'SELL': 1,\n    'HOLD': 2\n}\n\ndef map_label(x):\n    return label_mapping[x] if x in label_mapping else x","metadata":{"execution":{"iopub.status.busy":"2025-04-15T04:31:00.448272Z","iopub.execute_input":"2025-04-15T04:31:00.448684Z","iopub.status.idle":"2025-04-15T04:31:00.452362Z","shell.execute_reply.started":"2025-04-15T04:31:00.448661Z","shell.execute_reply":"2025-04-15T04:31:00.451582Z"},"trusted":true},"outputs":[],"execution_count":3},{"id":"6cbb91cd","cell_type":"code","source":"def load_shape(shape_path):\n    with open(shape_path, 'r') as f:\n        shape = f.readlines()\n        n_samples = int(shape[0])\n        seq_len = int(shape[1])\n        n_features = int(shape[2])\n    return n_samples, seq_len, n_features\n\nclass TradingDataset(Dataset):\n    def __init__(self, save_path, n_samples, sequence_length, n_features):\n        self.save_path = save_path\n        self.n_samples = n_samples\n        self.sequences = np.memmap(f'{save_path}/sequences.dat', dtype=np.float32, mode='r', \n                                 shape=(n_samples, sequence_length, n_features))\n        self.labels = np.memmap(f'{save_path}/labels.dat', dtype=np.int64, mode='r', \n                              shape=(n_samples,))\n    \n    def __len__(self):\n        return self.n_samples\n    \n    def __getitem__(self, idx):\n        seq = self.sequences[idx].copy()  # Tạo bản sao writable\n        lbl = self.labels[idx].copy()\n        return torch.from_numpy(seq).float(), torch.from_numpy(np.array([lbl])).long()[0]\n\ndef prepare_transformer_input(train_shape_path, val_shape_path, test_shape_path, data_path, batch_size=32):    \n    n_train_samples, sequence_length, n_features = load_shape(train_shape_path)\n    n_val_samples, _, _ = load_shape(val_shape_path)\n    n_test_samples, _, _ = load_shape(test_shape_path)\n    \n    train_path = f'{data_path}/train'\n    val_path = f'{data_path}/val'\n    test_path = f'{data_path}/test'\n    \n    # Tạo datasets\n    train_dataset = TradingDataset(train_path, n_train_samples, sequence_length, n_features)\n    val_dataset = TradingDataset(val_path, n_val_samples, sequence_length, n_features)\n    test_dataset = TradingDataset(test_path, n_test_samples, sequence_length, n_features)\n    \n    # Tạo dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    \n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2025-04-15T04:31:00.453632Z","iopub.execute_input":"2025-04-15T04:31:00.453941Z","iopub.status.idle":"2025-04-15T04:31:00.474790Z","shell.execute_reply.started":"2025-04-15T04:31:00.453913Z","shell.execute_reply":"2025-04-15T04:31:00.474003Z"},"trusted":true},"outputs":[],"execution_count":4},{"id":"fd11f2df-64e5-4a69-b2e8-f44d117fee49","cell_type":"code","source":"train_shape_path = '/kaggle/input/processed-xauusd/train/shape.txt'\nval_shape_path = '/kaggle/input/processed-xauusd/val/shape.txt'\ntest_shape_path = '/kaggle/input/processed-xauusd/test/shape.txt'\n\n\ntrain_loader, val_loader, test_loader = prepare_transformer_input(\n    train_shape_path, val_shape_path, test_shape_path,\n    data_path='/kaggle/input/processed-xauusd',\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T04:31:00.475856Z","iopub.execute_input":"2025-04-15T04:31:00.476155Z","iopub.status.idle":"2025-04-15T04:31:00.560698Z","shell.execute_reply.started":"2025-04-15T04:31:00.476125Z","shell.execute_reply":"2025-04-15T04:31:00.560119Z"},"trusted":true},"outputs":[],"execution_count":5},{"id":"4cd830e6","cell_type":"code","source":"# Kiểm tra\nsample_batch = next(iter(train_loader))\nprint(\"Batch input shape:\", sample_batch[0].shape)\nprint(\"Batch labels shape:\", sample_batch[1].shape)\nprint(\"\\nExample input shape for Transformer:\", sample_batch[0][0].shape)\nprint(sample_batch[0][0])\nprint(\"Number of batches:\", len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:00.561365Z","iopub.execute_input":"2025-04-15T04:31:00.561556Z","iopub.status.idle":"2025-04-15T04:31:00.817183Z","shell.execute_reply.started":"2025-04-15T04:31:00.561539Z","shell.execute_reply":"2025-04-15T04:31:00.816381Z"}},"outputs":[{"name":"stdout","text":"Batch input shape: torch.Size([32, 128, 27])\nBatch labels shape: torch.Size([32])\n\nExample input shape for Transformer: torch.Size([128, 27])\ntensor([[-0.7127, -0.7133, -0.7126,  ..., -0.6439,  0.8317,  0.8950],\n        [-0.7129, -0.7134, -0.7127,  ..., -0.6439,  0.8317,  0.8950],\n        [-0.7132, -0.7137, -0.7134,  ..., -0.6439,  0.8317,  0.8950],\n        ...,\n        [-0.7067, -0.7072, -0.7065,  ..., -1.1719,  0.8317,  0.8950],\n        [-0.7070, -0.7071, -0.7064,  ..., -1.1719,  0.8317,  0.8950],\n        [-0.7065, -0.7067, -0.7068,  ..., -1.1719,  0.8317,  0.8950]])\nNumber of batches: 3283\n","output_type":"stream"}],"execution_count":6},{"id":"d4d43dc8-a2af-42b7-a6f7-b2a893f5f70d","cell_type":"markdown","source":"# 3 - Build model","metadata":{}},{"id":"c95237f8-ac3c-47f5-b7da-e3b9fd3ba6b4","cell_type":"code","source":"class HybridTradingModel(nn.Module):\n    def __init__(self, num_features, num_classes=3, d_model=128, nhead=8, dim_feedforward=512, num_layers=3):\n        super().__init__()\n        \n        # 1. CNN Branch (cho feature extraction)\n        self.cnn = nn.Sequential(\n            nn.Conv1d(num_features, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        \n        # 2. Transformer Branch\n        self.transformer_proj = nn.Linear(num_features, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        \n        # 3. Fusion & Classification\n        self.fusion = nn.Linear(128 + d_model, 256)  # CNN output + Transformer output\n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        # x shape: [batch, seq_len, num_features]\n        \n        # CNN Path (requires [batch, channels, seq_len])\n        cnn_features = self.cnn(x.permute(0, 2, 1))  # [batch, 128, seq_len//2]\n        cnn_features = cnn_features.mean(dim=-1)      # Global Avg Pooling [batch, 128]\n        \n        # Transformer Path\n        transformer_features = self.transformer_proj(x)  # [batch, seq_len, d_model]\n        transformer_features = self.transformer(transformer_features)  # [batch, seq_len, d_model]\n        transformer_features = transformer_features.mean(dim=1)  # Pooling [batch, d_model]\n        \n        # Fusion\n        combined = torch.cat([cnn_features, transformer_features], dim=-1)\n        return self.classifier(self.fusion(combined))\n\nN_FEATURES = 27\nmodel = HybridTradingModel(num_features=N_FEATURES, num_classes=3, d_model=512, nhead=8, dim_feedforward=2048, num_layers=6)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T04:31:00.817817Z","iopub.execute_input":"2025-04-15T04:31:00.818081Z","iopub.status.idle":"2025-04-15T04:31:00.902600Z","shell.execute_reply.started":"2025-04-15T04:31:00.818059Z","shell.execute_reply":"2025-04-15T04:31:00.901894Z"},"trusted":true},"outputs":[],"execution_count":7},{"id":"d45736e4","cell_type":"code","source":"from torchinfo import summary\nprint(summary(model, (32, 128, 27)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:00.904664Z","iopub.execute_input":"2025-04-15T04:31:00.904898Z","iopub.status.idle":"2025-04-15T04:31:03.137327Z","shell.execute_reply.started":"2025-04-15T04:31:00.904857Z","shell.execute_reply":"2025-04-15T04:31:03.136533Z"}},"outputs":[{"name":"stdout","text":"===============================================================================================\nLayer (type:depth-idx)                        Output Shape              Param #\n===============================================================================================\nHybridTradingModel                            [32, 3]                   --\n├─Sequential: 1-1                             [32, 128, 64]             --\n│    └─Conv1d: 2-1                            [32, 64, 128]             5,248\n│    └─ReLU: 2-2                              [32, 64, 128]             --\n│    └─MaxPool1d: 2-3                         [32, 64, 64]              --\n│    └─Conv1d: 2-4                            [32, 128, 64]             24,704\n│    └─ReLU: 2-5                              [32, 128, 64]             --\n├─Linear: 1-2                                 [32, 128, 512]            14,336\n├─TransformerEncoder: 1-3                     [32, 128, 512]            --\n│    └─ModuleList: 2-6                        --                        --\n│    │    └─TransformerEncoderLayer: 3-1      [32, 128, 512]            3,152,384\n│    │    └─TransformerEncoderLayer: 3-2      [32, 128, 512]            3,152,384\n│    │    └─TransformerEncoderLayer: 3-3      [32, 128, 512]            3,152,384\n│    │    └─TransformerEncoderLayer: 3-4      [32, 128, 512]            3,152,384\n│    │    └─TransformerEncoderLayer: 3-5      [32, 128, 512]            3,152,384\n│    │    └─TransformerEncoderLayer: 3-6      [32, 128, 512]            3,152,384\n├─Linear: 1-4                                 [32, 256]                 164,096\n├─Sequential: 1-5                             [32, 3]                   --\n│    └─Linear: 2-7                            [32, 128]                 32,896\n│    └─ReLU: 2-8                              [32, 128]                 --\n│    └─Dropout: 2-9                           [32, 128]                 --\n│    └─Linear: 2-10                           [32, 3]                   387\n===============================================================================================\nTotal params: 19,155,971\nTrainable params: 19,155,971\nNon-trainable params: 0\nTotal mult-adds (M): 482.40\n===============================================================================================\nInput size (MB): 0.44\nForward/backward pass size (MB): 725.71\nParams size (MB): 51.41\nEstimated Total Size (MB): 777.57\n===============================================================================================\n","output_type":"stream"}],"execution_count":8},{"id":"652895ef","cell_type":"code","source":"# model(sample_batch[0]).shape, sample_batch[1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:03.138525Z","iopub.execute_input":"2025-04-15T04:31:03.138735Z","iopub.status.idle":"2025-04-15T04:31:03.141998Z","shell.execute_reply.started":"2025-04-15T04:31:03.138717Z","shell.execute_reply":"2025-04-15T04:31:03.141094Z"}},"outputs":[],"execution_count":9},{"id":"f51a2649-7985-4b80-991c-0b8223d43884","cell_type":"markdown","source":"# 4 - Train and Evaluate model","metadata":{}},{"id":"c9760660","cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=3, min_delta=0.001):\n        \"\"\"\n        patience: Số epoch chờ mà không cải thiện trước khi dừng\n        min_delta: Độ cải thiện tối thiểu để coi là tốt hơn\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter}/{self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n            \ndef eval_model(model, val_loader, criterion, device):\n    model.to(device)\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, unit='batch', desc='\\tEvaluating: '):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, -1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(val_loader)\n    epoch_acc = 100 * correct / total\n    \n    return epoch_loss, epoch_acc\n\ndef train_model(model, train_loader, criterion, optimizer, device, scheduler=None):\n    model.to(device)\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n        \n    for images, labels in tqdm(train_loader, unit='batch', desc=f'\\tTraining: '):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, -1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100 * correct / total\n\n    if scheduler is not None:\n        scheduler.step()\n    \n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:03.142660Z","iopub.execute_input":"2025-04-15T04:31:03.142840Z","iopub.status.idle":"2025-04-15T04:31:03.163468Z","shell.execute_reply.started":"2025-04-15T04:31:03.142824Z","shell.execute_reply":"2025-04-15T04:31:03.162904Z"}},"outputs":[],"execution_count":10},{"id":"8adff6f0","cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nn_train_samples, _, _ = load_shape('/kaggle/input/processed-xauusd/train/shape.txt')\ntrain_labels = np.memmap(f'/kaggle/input/processed-xauusd/train/labels.dat', dtype=np.int64, mode='r', \n                              shape=(n_train_samples,))\nclass_weights = compute_class_weight(\n    'balanced', \n    classes=np.unique(train_labels), \n    y=train_labels\n)\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(DEVICE))\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:03.164108Z","iopub.execute_input":"2025-04-15T04:31:03.164284Z","iopub.status.idle":"2025-04-15T04:31:05.635597Z","shell.execute_reply.started":"2025-04-15T04:31:03.164268Z","shell.execute_reply":"2025-04-15T04:31:05.634957Z"}},"outputs":[],"execution_count":11},{"id":"5423930c","cell_type":"code","source":"NUM_EPOCHS = 20\nPATIENCE = 3\nMIN_DELTA = 0.0005\ntorch.cuda.empty_cache()\n\nmodel = nn.DataParallel(model)\n    \ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\n\nearly_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA)\n\nfor epoch in range(NUM_EPOCHS):\n    print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}]')\n    \n    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, DEVICE)\n    val_loss, val_acc = eval_model(model, val_loader, criterion, DEVICE)\n    \n    print(f'\\tTrain Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n    print(f'\\tVal Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%')\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    \n    # Kiểm tra Early Stopping\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered!\")\n        break\n    print('===================================================')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:31:05.636278Z","iopub.execute_input":"2025-04-15T04:31:05.636605Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [06:06<00:00,  8.96batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:41<00:00, 26.73batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0588, Train Accuracy: 47.35%\n\tVal Loss: 1.0761, Val Accuracy: 45.59%\n===================================================\nEpoch [2/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [05:56<00:00,  9.20batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:36<00:00, 29.67batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0527, Train Accuracy: 48.93%\n\tVal Loss: 1.0691, Val Accuracy: 44.00%\n===================================================\nEpoch [3/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [05:57<00:00,  9.19batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:36<00:00, 29.97batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0498, Train Accuracy: 49.35%\n\tVal Loss: 1.0671, Val Accuracy: 42.62%\n===================================================\nEpoch [4/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [05:56<00:00,  9.21batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:36<00:00, 30.12batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0490, Train Accuracy: 49.03%\n\tVal Loss: 1.0653, Val Accuracy: 43.03%\n===================================================\nEpoch [5/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [05:56<00:00,  9.22batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:36<00:00, 30.30batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0469, Train Accuracy: 49.60%\n\tVal Loss: 1.0648, Val Accuracy: 43.27%\nEarlyStopping counter: 1/3\n===================================================\nEpoch [6/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining: 100%|██████████| 3283/3283 [05:55<00:00,  9.22batch/s]\n\tEvaluating: 100%|██████████| 1097/1097 [00:36<00:00, 30.06batch/s]\n","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss: 1.0446, Train Accuracy: 49.29%\n\tVal Loss: 1.0639, Val Accuracy: 42.58%\n===================================================\nEpoch [7/20]\n","output_type":"stream"},{"name":"stderr","text":"\tTraining:  60%|██████    | 1981/3283 [03:34<02:20,  9.24batch/s]","output_type":"stream"}],"execution_count":null},{"id":"829afcde","cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training_results(train_losses, train_accs, val_losses, val_accs):\n    \"\"\"\n    Vẽ biểu đồ kết quả huấn luyện: loss và accuracy cho train và validation.\n    \n    Parameters:\n    - train_losses: List các giá trị loss của train qua các epoch\n    - train_accs: List các giá trị accuracy của train qua các epoch\n    - val_losses: List các giá trị loss của validation qua các epoch\n    - val_accs: List các giá trị accuracy của validation qua các epoch\n    \"\"\"\n    epochs = range(1, len(train_losses) + 1)\n    \n    # Tạo figure với 2x2 subplot\n    plt.figure(figsize=(12, 8))\n    \n    # Subplot 1: Train Loss\n    plt.subplot(2, 2, 1)\n    plt.plot(epochs, train_losses, 'b-', label='Train Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 2: Train Accuracy\n    plt.subplot(2, 2, 2)\n    plt.plot(epochs, train_accs, 'g-', label='Train Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Training Accuracy')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 3: Validation Loss\n    plt.subplot(2, 2, 3)\n    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 4: Validation Accuracy\n    plt.subplot(2, 2, 4)\n    plt.plot(epochs, val_accs, 'm-', label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n    \n    # Điều chỉnh layout và hiển thị\n    plt.tight_layout()\n    plt.show()\n\nplot_training_results(train_losses, train_accs, val_losses, val_accs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7ac6557f","cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a4c00022-b206-4e78-a66c-7cc765a9df91","cell_type":"code","source":"def test_model(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    model.to(device)\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch_x, batch_y in test_loader:\n            batch_x = batch_x.to(device)  # [B, seq_len, n_features]\n            batch_y = batch_y.to(device)\n\n            outputs = model(batch_x)  # Expecting [B, num_classes]\n            preds = torch.argmax(outputs, dim=-1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(batch_y.cpu().numpy())\n\n    target_names = ['BUY', 'SELL', 'HOLD']\n    cm = confusion_matrix(all_labels, all_preds)\n    print('Confusion matrix:')\n    print(pd.DataFrame(cm, columns=target_names, index=target_names))\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4, zero_division=0))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"72707918-5b2b-475e-870d-20facf485d28","cell_type":"code","source":"test_model(model, train_loader, DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3e8f69e6-0280-4e85-a630-0123a92807c3","cell_type":"code","source":"test_model(model, val_loader, DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b7304e54-da55-4d87-8442-fd7277fbd3ee","cell_type":"code","source":"test_model(model, test_loader, DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d5294e71-05dc-4645-bc83-16f924b60b39","cell_type":"code","source":"def get_prediction(model, inputs, device):\n    # inputs = [B, S, N]\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        preds = torch.argmax(outputs, dim=-1)\n    return preds.cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d9d79f9e-021a-44f6-af02-b8dd96dfe311","cell_type":"code","source":"batch = next(iter(test_loader))\ninputs, labels = batch[0], batch[1]\n\nget_prediction(model, inputs, DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"79d98d9f-1913-4077-b286-24e5f441f7cc","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}